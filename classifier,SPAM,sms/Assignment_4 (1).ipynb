{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/ranjeetkumbhar/ml-assignment-4-te-it-sppu?scriptVersionId=110429853\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "814debf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:35.003859Z",
     "iopub.status.busy": "2022-11-08T18:14:35.002535Z",
     "iopub.status.idle": "2022-11-08T18:14:35.024404Z",
     "shell.execute_reply": "2022-11-08T18:14:35.022354Z"
    },
    "papermill": {
     "duration": 0.040783,
     "end_time": "2022-11-08T18:14:35.027762",
     "exception": false,
     "start_time": "2022-11-08T18:14:34.986979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b718797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:35.053501Z",
     "iopub.status.busy": "2022-11-08T18:14:35.052294Z",
     "iopub.status.idle": "2022-11-08T18:14:35.058148Z",
     "shell.execute_reply": "2022-11-08T18:14:35.056835Z"
    },
    "papermill": {
     "duration": 0.021229,
     "end_time": "2022-11-08T18:14:35.061007",
     "exception": false,
     "start_time": "2022-11-08T18:14:35.039778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f69e242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:35.08678Z",
     "iopub.status.busy": "2022-11-08T18:14:35.085524Z",
     "iopub.status.idle": "2022-11-08T18:14:35.142742Z",
     "shell.execute_reply": "2022-11-08T18:14:35.140996Z"
    },
    "papermill": {
     "duration": 0.073756,
     "end_time": "2022-11-08T18:14:35.145936",
     "exception": false,
     "start_time": "2022-11-08T18:14:35.07218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('SMSSpamCollection',sep='\\t',names=['label','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ce91d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:35.17032Z",
     "iopub.status.busy": "2022-11-08T18:14:35.169901Z",
     "iopub.status.idle": "2022-11-08T18:14:35.205323Z",
     "shell.execute_reply": "2022-11-08T18:14:35.204068Z"
    },
    "papermill": {
     "duration": 0.05186,
     "end_time": "2022-11-08T18:14:35.209119",
     "exception": false,
     "start_time": "2022-11-08T18:14:35.157259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4aca8d",
   "metadata": {
    "papermill": {
     "duration": 0.01099,
     "end_time": "2022-11-08T18:14:35.232134",
     "exception": false,
     "start_time": "2022-11-08T18:14:35.221144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6753224f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:35.257144Z",
     "iopub.status.busy": "2022-11-08T18:14:35.256448Z",
     "iopub.status.idle": "2022-11-08T18:14:35.263193Z",
     "shell.execute_reply": "2022-11-08T18:14:35.261863Z"
    },
    "papermill": {
     "duration": 0.023807,
     "end_time": "2022-11-08T18:14:35.267369",
     "exception": false,
     "start_time": "2022-11-08T18:14:35.243562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22df78d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:35.29246Z",
     "iopub.status.busy": "2022-11-08T18:14:35.29202Z",
     "iopub.status.idle": "2022-11-08T18:14:37.043822Z",
     "shell.execute_reply": "2022-11-08T18:14:37.042739Z"
    },
    "papermill": {
     "duration": 1.768252,
     "end_time": "2022-11-08T18:14:37.047258",
     "exception": false,
     "start_time": "2022-11-08T18:14:35.279006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk #!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70d92783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.07183Z",
     "iopub.status.busy": "2022-11-08T18:14:37.071168Z",
     "iopub.status.idle": "2022-11-08T18:14:37.227557Z",
     "shell.execute_reply": "2022-11-08T18:14:37.225394Z"
    },
    "papermill": {
     "duration": 0.173277,
     "end_time": "2022-11-08T18:14:37.231686",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.058409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Purvesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63d75c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.257878Z",
     "iopub.status.busy": "2022-11-08T18:14:37.257004Z",
     "iopub.status.idle": "2022-11-08T18:14:37.262554Z",
     "shell.execute_reply": "2022-11-08T18:14:37.26159Z"
    },
    "papermill": {
     "duration": 0.021557,
     "end_time": "2022-11-08T18:14:37.264962",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.243405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sent = 'How are you friends?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56d45f6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.290738Z",
     "iopub.status.busy": "2022-11-08T18:14:37.290323Z",
     "iopub.status.idle": "2022-11-08T18:14:37.313336Z",
     "shell.execute_reply": "2022-11-08T18:14:37.312183Z"
    },
    "papermill": {
     "duration": 0.038883,
     "end_time": "2022-11-08T18:14:37.31568",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.276797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Purvesh/nltk_data'\n    - 'c:\\\\Users\\\\Purvesh\\\\anaconda3\\\\nltk_data'\n    - 'c:\\\\Users\\\\Purvesh\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Purvesh\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Purvesh\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m----> 2\u001b[0m word_tokenize(sent)\n",
      "File \u001b[1;32mc:\\Users\\Purvesh\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Purvesh\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers/punkt/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32mc:\\Users\\Purvesh\\anaconda3\\Lib\\site-packages\\nltk\\data.py:750\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m _open(resource_url)\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\Purvesh\\anaconda3\\Lib\\site-packages\\nltk\\data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, path \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[1;32mc:\\Users\\Purvesh\\anaconda3\\Lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Purvesh/nltk_data'\n    - 'c:\\\\Users\\\\Purvesh\\\\anaconda3\\\\nltk_data'\n    - 'c:\\\\Users\\\\Purvesh\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Purvesh\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Purvesh\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd381b3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.341217Z",
     "iopub.status.busy": "2022-11-08T18:14:37.34057Z",
     "iopub.status.idle": "2022-11-08T18:14:37.348263Z",
     "shell.execute_reply": "2022-11-08T18:14:37.347335Z"
    },
    "papermill": {
     "duration": 0.023175,
     "end_time": "2022-11-08T18:14:37.350758",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.327583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "swords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0072e5ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.375571Z",
     "iopub.status.busy": "2022-11-08T18:14:37.375146Z",
     "iopub.status.idle": "2022-11-08T18:14:37.381114Z",
     "shell.execute_reply": "2022-11-08T18:14:37.379678Z"
    },
    "papermill": {
     "duration": 0.02125,
     "end_time": "2022-11-08T18:14:37.383462",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.362212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Purvesh/nltk_data'\n    - 'c:\\\\Users\\\\Purvesh\\\\anaconda3\\\\nltk_data'\n    - 'c:\\\\Users\\\\Purvesh\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Purvesh\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Purvesh\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clean \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_tokenize(sent) \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m swords]\n",
      "File \u001b[1;32mc:\\Users\\Purvesh\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Purvesh\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers/punkt/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32mc:\\Users\\Purvesh\\anaconda3\\Lib\\site-packages\\nltk\\data.py:750\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m _open(resource_url)\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\Purvesh\\anaconda3\\Lib\\site-packages\\nltk\\data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, path \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[1;32mc:\\Users\\Purvesh\\anaconda3\\Lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Purvesh/nltk_data'\n    - 'c:\\\\Users\\\\Purvesh\\\\anaconda3\\\\nltk_data'\n    - 'c:\\\\Users\\\\Purvesh\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Purvesh\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Purvesh\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "clean = [word for word in word_tokenize(sent) if word not in swords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ec27a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.40902Z",
     "iopub.status.busy": "2022-11-08T18:14:37.407628Z",
     "iopub.status.idle": "2022-11-08T18:14:37.415093Z",
     "shell.execute_reply": "2022-11-08T18:14:37.414145Z"
    },
    "papermill": {
     "duration": 0.022393,
     "end_time": "2022-11-08T18:14:37.41721",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.394817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clean()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clean' is not defined"
     ]
    }
   ],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4645c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.443267Z",
     "iopub.status.busy": "2022-11-08T18:14:37.441875Z",
     "iopub.status.idle": "2022-11-08T18:14:37.450497Z",
     "shell.execute_reply": "2022-11-08T18:14:37.44961Z"
    },
    "papermill": {
     "duration": 0.023796,
     "end_time": "2022-11-08T18:14:37.452612",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.428816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stemming words with NLTK\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "clean = [ps.stem(word) for word in word_tokenize(sent) \n",
    "         if word not in swords]\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5f3f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.479186Z",
     "iopub.status.busy": "2022-11-08T18:14:37.477615Z",
     "iopub.status.idle": "2022-11-08T18:14:37.483248Z",
     "shell.execute_reply": "2022-11-08T18:14:37.482366Z"
    },
    "papermill": {
     "duration": 0.021418,
     "end_time": "2022-11-08T18:14:37.485664",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.464246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sent = 'Hello friends! How are you? We will learning python today'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8995d967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.512601Z",
     "iopub.status.busy": "2022-11-08T18:14:37.511774Z",
     "iopub.status.idle": "2022-11-08T18:14:37.518082Z",
     "shell.execute_reply": "2022-11-08T18:14:37.516853Z"
    },
    "papermill": {
     "duration": 0.022807,
     "end_time": "2022-11-08T18:14:37.520654",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.497847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(sent):\n",
    "    tokens = word_tokenize(sent)\n",
    "    clean = [word for word in tokens if word.isdigit() or word.isalpha()]\n",
    "    clean = [ps.stem(word) for word in clean\n",
    "         if word not in swords]\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9b6b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.547518Z",
     "iopub.status.busy": "2022-11-08T18:14:37.547005Z",
     "iopub.status.idle": "2022-11-08T18:14:37.557411Z",
     "shell.execute_reply": "2022-11-08T18:14:37.556085Z"
    },
    "papermill": {
     "duration": 0.027166,
     "end_time": "2022-11-08T18:14:37.56005",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.532884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_text(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653276ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.587078Z",
     "iopub.status.busy": "2022-11-08T18:14:37.585941Z",
     "iopub.status.idle": "2022-11-08T18:14:37.591197Z",
     "shell.execute_reply": "2022-11-08T18:14:37.590269Z"
    },
    "papermill": {
     "duration": 0.021166,
     "end_time": "2022-11-08T18:14:37.593417",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.572251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-processing \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5009a272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.61971Z",
     "iopub.status.busy": "2022-11-08T18:14:37.619269Z",
     "iopub.status.idle": "2022-11-08T18:14:37.624114Z",
     "shell.execute_reply": "2022-11-08T18:14:37.622961Z"
    },
    "papermill": {
     "duration": 0.020873,
     "end_time": "2022-11-08T18:14:37.626317",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.605444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer=clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e09b654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.652908Z",
     "iopub.status.busy": "2022-11-08T18:14:37.651741Z",
     "iopub.status.idle": "2022-11-08T18:14:37.661377Z",
     "shell.execute_reply": "2022-11-08T18:14:37.660429Z"
    },
    "papermill": {
     "duration": 0.02518,
     "end_time": "2022-11-08T18:14:37.663584",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.638404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = df['text']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a148a8db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:37.690279Z",
     "iopub.status.busy": "2022-11-08T18:14:37.688825Z",
     "iopub.status.idle": "2022-11-08T18:14:40.820874Z",
     "shell.execute_reply": "2022-11-08T18:14:40.819509Z"
    },
    "papermill": {
     "duration": 3.148943,
     "end_time": "2022-11-08T18:14:40.824268",
     "exception": false,
     "start_time": "2022-11-08T18:14:37.675325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_new = tfidf.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7479ccab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:40.851598Z",
     "iopub.status.busy": "2022-11-08T18:14:40.851115Z",
     "iopub.status.idle": "2022-11-08T18:14:40.859519Z",
     "shell.execute_reply": "2022-11-08T18:14:40.858126Z"
    },
    "papermill": {
     "duration": 0.025655,
     "end_time": "2022-11-08T18:14:40.862469",
     "exception": false,
     "start_time": "2022-11-08T18:14:40.836814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32eaf28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:40.889522Z",
     "iopub.status.busy": "2022-11-08T18:14:40.888786Z",
     "iopub.status.idle": "2022-11-08T18:14:40.894957Z",
     "shell.execute_reply": "2022-11-08T18:14:40.893971Z"
    },
    "papermill": {
     "duration": 0.022336,
     "end_time": "2022-11-08T18:14:40.897188",
     "exception": false,
     "start_time": "2022-11-08T18:14:40.874852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ecac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:40.924526Z",
     "iopub.status.busy": "2022-11-08T18:14:40.923792Z",
     "iopub.status.idle": "2022-11-08T18:14:40.928584Z",
     "shell.execute_reply": "2022-11-08T18:14:40.927043Z"
    },
    "papermill": {
     "duration": 0.02147,
     "end_time": "2022-11-08T18:14:40.930993",
     "exception": false,
     "start_time": "2022-11-08T18:14:40.909523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941b2f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:40.957192Z",
     "iopub.status.busy": "2022-11-08T18:14:40.956664Z",
     "iopub.status.idle": "2022-11-08T18:14:41.414311Z",
     "shell.execute_reply": "2022-11-08T18:14:41.412733Z"
    },
    "papermill": {
     "duration": 0.474338,
     "end_time": "2022-11-08T18:14:41.417231",
     "exception": false,
     "start_time": "2022-11-08T18:14:40.942893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d454e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:41.443543Z",
     "iopub.status.busy": "2022-11-08T18:14:41.443094Z",
     "iopub.status.idle": "2022-11-08T18:14:41.453447Z",
     "shell.execute_reply": "2022-11-08T18:14:41.452109Z"
    },
    "papermill": {
     "duration": 0.026937,
     "end_time": "2022-11-08T18:14:41.456451",
     "exception": false,
     "start_time": "2022-11-08T18:14:41.429514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_new,y,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93247249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:41.48433Z",
     "iopub.status.busy": "2022-11-08T18:14:41.483799Z",
     "iopub.status.idle": "2022-11-08T18:14:41.491969Z",
     "shell.execute_reply": "2022-11-08T18:14:41.489993Z"
    },
    "papermill": {
     "duration": 0.025483,
     "end_time": "2022-11-08T18:14:41.494894",
     "exception": false,
     "start_time": "2022-11-08T18:14:41.469411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Size of splitted data\")\n",
    "print(f\"x_train {x_train.shape}\")\n",
    "print(f\"y_train {y_train.shape}\")\n",
    "print(f\"y_test {x_test.shape}\")\n",
    "print(f\"y_test {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a33689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:41.52176Z",
     "iopub.status.busy": "2022-11-08T18:14:41.521179Z",
     "iopub.status.idle": "2022-11-08T18:14:41.528931Z",
     "shell.execute_reply": "2022-11-08T18:14:41.527963Z"
    },
    "papermill": {
     "duration": 0.024168,
     "end_time": "2022-11-08T18:14:41.531219",
     "exception": false,
     "start_time": "2022-11-08T18:14:41.507051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9746cf0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:41.558911Z",
     "iopub.status.busy": "2022-11-08T18:14:41.557288Z",
     "iopub.status.idle": "2022-11-08T18:14:42.581294Z",
     "shell.execute_reply": "2022-11-08T18:14:42.579825Z"
    },
    "papermill": {
     "duration": 1.041189,
     "end_time": "2022-11-08T18:14:42.58464",
     "exception": false,
     "start_time": "2022-11-08T18:14:41.543451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(x_train.toarray(),y_train)\n",
    "y_pred_nb = nb.predict(x_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c4b6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:42.6129Z",
     "iopub.status.busy": "2022-11-08T18:14:42.612494Z",
     "iopub.status.idle": "2022-11-08T18:14:42.623891Z",
     "shell.execute_reply": "2022-11-08T18:14:42.622539Z"
    },
    "papermill": {
     "duration": 0.028688,
     "end_time": "2022-11-08T18:14:42.626514",
     "exception": false,
     "start_time": "2022-11-08T18:14:42.597826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c51dac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:42.655816Z",
     "iopub.status.busy": "2022-11-08T18:14:42.654652Z",
     "iopub.status.idle": "2022-11-08T18:14:42.662005Z",
     "shell.execute_reply": "2022-11-08T18:14:42.660357Z"
    },
    "papermill": {
     "duration": 0.025572,
     "end_time": "2022-11-08T18:14:42.66532",
     "exception": false,
     "start_time": "2022-11-08T18:14:42.639748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3190c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:42.693563Z",
     "iopub.status.busy": "2022-11-08T18:14:42.692706Z",
     "iopub.status.idle": "2022-11-08T18:14:42.98215Z",
     "shell.execute_reply": "2022-11-08T18:14:42.980801Z"
    },
    "papermill": {
     "duration": 0.307516,
     "end_time": "2022-11-08T18:14:42.985957",
     "exception": false,
     "start_time": "2022-11-08T18:14:42.678441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test,y_pred_nb)\n",
    "plt.title('Naive bayes')\n",
    "plt.show()\n",
    "print(f\" Accuracy is {accuracy_score(y_test,y_pred_nb)}\")\n",
    "print(classification_report(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379cedf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:43.015246Z",
     "iopub.status.busy": "2022-11-08T18:14:43.014744Z",
     "iopub.status.idle": "2022-11-08T18:14:47.193194Z",
     "shell.execute_reply": "2022-11-08T18:14:47.191769Z"
    },
    "papermill": {
     "duration": 4.196292,
     "end_time": "2022-11-08T18:14:47.196319",
     "exception": false,
     "start_time": "2022-11-08T18:14:43.000027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(random_state=1)\n",
    "model_rf.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c8de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:47.225884Z",
     "iopub.status.busy": "2022-11-08T18:14:47.225366Z",
     "iopub.status.idle": "2022-11-08T18:14:47.315712Z",
     "shell.execute_reply": "2022-11-08T18:14:47.314707Z"
    },
    "papermill": {
     "duration": 0.108288,
     "end_time": "2022-11-08T18:14:47.318405",
     "exception": false,
     "start_time": "2022-11-08T18:14:47.210117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_rf = model_rf.predict(x_test) #float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6478f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:47.348653Z",
     "iopub.status.busy": "2022-11-08T18:14:47.347309Z",
     "iopub.status.idle": "2022-11-08T18:14:47.635245Z",
     "shell.execute_reply": "2022-11-08T18:14:47.633566Z"
    },
    "papermill": {
     "duration": 0.307309,
     "end_time": "2022-11-08T18:14:47.639006",
     "exception": false,
     "start_time": "2022-11-08T18:14:47.331697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test,y_pred_rf)\n",
    "plt.title('Random Forest')\n",
    "plt.show()\n",
    "print(f\" Accuracy is {accuracy_score(y_test,y_pred_rf)}\")\n",
    "print(classification_report(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8298d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:47.670104Z",
     "iopub.status.busy": "2022-11-08T18:14:47.669709Z",
     "iopub.status.idle": "2022-11-08T18:14:47.744556Z",
     "shell.execute_reply": "2022-11-08T18:14:47.743082Z"
    },
    "papermill": {
     "duration": 0.093694,
     "end_time": "2022-11-08T18:14:47.747752",
     "exception": false,
     "start_time": "2022-11-08T18:14:47.654058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lr = LogisticRegression(random_state=1)\n",
    "\n",
    "model_lr.fit(x_train,y_train)\n",
    "y_pred_lr = model_lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec3c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:47.779184Z",
     "iopub.status.busy": "2022-11-08T18:14:47.778769Z",
     "iopub.status.idle": "2022-11-08T18:14:48.070046Z",
     "shell.execute_reply": "2022-11-08T18:14:48.067721Z"
    },
    "papermill": {
     "duration": 0.310222,
     "end_time": "2022-11-08T18:14:48.072879",
     "exception": false,
     "start_time": "2022-11-08T18:14:47.762657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test,y_pred_lr)\n",
    "plt.title('Logistic regression')\n",
    "plt.show()\n",
    "print(f\" Accuracy is {accuracy_score(y_test,y_pred_lr)}\")\n",
    "print(classification_report(y_test,y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f907dc50",
   "metadata": {
    "papermill": {
     "duration": 0.013419,
     "end_time": "2022-11-08T18:14:48.100086",
     "exception": false,
     "start_time": "2022-11-08T18:14:48.086667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hyper parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760fb237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:48.130534Z",
     "iopub.status.busy": "2022-11-08T18:14:48.129109Z",
     "iopub.status.idle": "2022-11-08T18:14:48.136504Z",
     "shell.execute_reply": "2022-11-08T18:14:48.135463Z"
    },
    "papermill": {
     "duration": 0.025469,
     "end_time": "2022-11-08T18:14:48.1394",
     "exception": false,
     "start_time": "2022-11-08T18:14:48.113931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be99044",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:48.1718Z",
     "iopub.status.busy": "2022-11-08T18:14:48.17135Z",
     "iopub.status.idle": "2022-11-08T18:14:48.17779Z",
     "shell.execute_reply": "2022-11-08T18:14:48.176207Z"
    },
    "papermill": {
     "duration": 0.026377,
     "end_time": "2022-11-08T18:14:48.180602",
     "exception": false,
     "start_time": "2022-11-08T18:14:48.154225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "para = {\n",
    "    \n",
    "    'criterion':['gini', 'entropy','log_loss'],\n",
    "#     'max_features': ['sqrt','log2'],\n",
    "#     'random_state': [0,1,2,3,4],\n",
    "    'class_weight':['balanced','balanced_subsample']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28217c35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:48.212266Z",
     "iopub.status.busy": "2022-11-08T18:14:48.211813Z",
     "iopub.status.idle": "2022-11-08T18:14:48.219464Z",
     "shell.execute_reply": "2022-11-08T18:14:48.217573Z"
    },
    "papermill": {
     "duration": 0.027029,
     "end_time": "2022-11-08T18:14:48.222183",
     "exception": false,
     "start_time": "2022-11-08T18:14:48.195154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(model_rf, param_grid=para, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a7e43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:14:48.25528Z",
     "iopub.status.busy": "2022-11-08T18:14:48.254878Z",
     "iopub.status.idle": "2022-11-08T18:15:47.675963Z",
     "shell.execute_reply": "2022-11-08T18:15:47.67437Z"
    },
    "papermill": {
     "duration": 59.440443,
     "end_time": "2022-11-08T18:15:47.678803",
     "exception": false,
     "start_time": "2022-11-08T18:14:48.23836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e9eba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:15:47.709063Z",
     "iopub.status.busy": "2022-11-08T18:15:47.708364Z",
     "iopub.status.idle": "2022-11-08T18:15:47.715604Z",
     "shell.execute_reply": "2022-11-08T18:15:47.714322Z"
    },
    "papermill": {
     "duration": 0.025539,
     "end_time": "2022-11-08T18:15:47.71833",
     "exception": false,
     "start_time": "2022-11-08T18:15:47.692791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe0bf27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:15:47.747433Z",
     "iopub.status.busy": "2022-11-08T18:15:47.747025Z",
     "iopub.status.idle": "2022-11-08T18:15:47.830778Z",
     "shell.execute_reply": "2022-11-08T18:15:47.829386Z"
    },
    "papermill": {
     "duration": 0.101846,
     "end_time": "2022-11-08T18:15:47.833926",
     "exception": false,
     "start_time": "2022-11-08T18:15:47.73208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_grid = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a37f8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T18:15:47.863723Z",
     "iopub.status.busy": "2022-11-08T18:15:47.863263Z",
     "iopub.status.idle": "2022-11-08T18:15:48.167592Z",
     "shell.execute_reply": "2022-11-08T18:15:48.165538Z"
    },
    "papermill": {
     "duration": 0.322527,
     "end_time": "2022-11-08T18:15:48.170588",
     "exception": false,
     "start_time": "2022-11-08T18:15:47.848061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test,y_pred_grid)\n",
    "plt.title('Gride Search')\n",
    "plt.show()\n",
    "print(f\" Accuracy is {accuracy_score(y_test,y_pred_grid)}\")\n",
    "print(classification_report(y_test,y_pred_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231257ac",
   "metadata": {
    "papermill": {
     "duration": 0.013783,
     "end_time": "2022-11-08T18:15:48.19887",
     "exception": false,
     "start_time": "2022-11-08T18:15:48.185087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 84.975286,
   "end_time": "2022-11-08T18:15:49.138354",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-08T18:14:24.163068",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
